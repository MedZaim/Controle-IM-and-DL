{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:25.520118700Z",
     "start_time": "2026-01-14T17:15:25.473737Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to Python path\n",
    "sys.path.append('..')\n",
    "\n",
    "from models import CustomCNN, VGG16, ViT\n",
    "\n",
    "print(\"✅ Dependencies loaded. Using device:\", \"GPU\" if torch.cuda.is_available() else \"CPU\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dependencies loaded. Using device: CPU\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:25.596533600Z",
     "start_time": "2026-01-14T17:15:25.540372600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Function to load and preprocess an image\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image to 64x64, normalized like in training.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # [-1, 1]\n",
    "    ])\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    return img_tensor"
   ],
   "id": "5eda84a92030eede",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:26.609045900Z",
     "start_time": "2026-01-14T17:15:25.640560500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Initialize and load trained models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model instances (same architecture as Étape 1)\n",
    "models_dict = {\n",
    "    \"Custom CNN\": CustomCNN(),\n",
    "    \"VGG16\": VGG16(),\n",
    "    \"ViT-1\": ViT(n_blocks=1),\n",
    "    \"ViT-2\": ViT(n_blocks=2)\n",
    "}\n",
    "\n",
    "# Paths to saved weights\n",
    "model_paths = {\n",
    "    \"Custom CNN\": \"../etape1/models/CustomCNN.pth\",\n",
    "    \"VGG16\": \"../etape1/models/VGG16.pth\",\n",
    "    \"ViT-1\": \"../etape1/models/ViT-1.pth\",  # Changed from ViT_1.pth\n",
    "    \"ViT-2\": \"../etape1/models/ViT-2.pth\"   # Changed from ViT_2.pth\n",
    "}\n",
    "\n",
    "# Load state dicts\n",
    "for name, model in models_dict.items():\n",
    "    if not os.path.exists(model_paths[name]):\n",
    "        raise FileNotFoundError(f\"Missing model file: {model_paths[name]}\")\n",
    "    model.load_state_dict(torch.load(model_paths[name], map_location=device, weights_only=True))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\":-) All 4 models loaded successfully.\")"
   ],
   "id": "94a668d3b573b29a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-) All 4 models loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:26.642581400Z",
     "start_time": "2026-01-14T17:15:26.626719300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 4: Run prediction on a given image path\n",
    "def predict_image(image_path):\n",
    "    print(f\"\\n==> Analyzing: {os.path.basename(image_path)}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Load and move image to device\n",
    "    img = load_image(image_path).to(device)\n",
    "\n",
    "    # Predict with each model\n",
    "    for name, model in models_dict.items():\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "\n",
    "        label = \"Malade\" if predicted_class == 1 else \"Saine\"\n",
    "        print(f\"{name:15} → {label} (confiance: {confidence:.3f})\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ],
   "id": "ff60d0c50522c3f1",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:26.750693400Z",
     "start_time": "2026-01-14T17:15:26.642581400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 5: Example usage\n",
    "# Replace this path with any image you want to test\n",
    "test_image_path = \"test_images/ISIC_0024306_0.jpg\"  # ← put a test image in your folder\n",
    "#test_image_path = \"test_images/ISIC_0024313_1.jpg\"\n",
    "\n",
    "# Optional: upload an image if running on Colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# test_image_path = list(uploaded.keys())[0]\n",
    "\n",
    "# Run prediction\n",
    "try:\n",
    "    predict_image(test_image_path)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    print(\"\\n Tip: Place an image (e.g., 'test.jpg') in this folder and update the path above.\")"
   ],
   "id": "7a22c6a6c98cda68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Analyzing: ISIC_0024306_0.jpg\n",
      "\n",
      "--------------------------------------------------\n",
      "Custom CNN      → Saine (confiance: 0.919)\n",
      "VGG16           → Saine (confiance: 0.926)\n",
      "ViT-1           → Saine (confiance: 1.000)\n",
      "ViT-2           → Saine (confiance: 1.000)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:26.901059700Z",
     "start_time": "2026-01-14T17:15:26.750693400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 6 (Optional): Predict multiple images\n",
    "test_folder = \"test_images/\"  # create this folder with images\n",
    "\n",
    "if os.path.exists(test_folder):\n",
    "    for img_name in os.listdir(test_folder):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            predict_image(os.path.join(test_folder, img_name))\n",
    "else:\n",
    "    print(\" No 'test_images' folder found. Skip batch prediction.\")"
   ],
   "id": "3c5d21c60d217f39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Analyzing: ISIC_0024306_0.jpg\n",
      "\n",
      "--------------------------------------------------\n",
      "Custom CNN      → Saine (confiance: 0.919)\n",
      "VGG16           → Saine (confiance: 0.926)\n",
      "ViT-1           → Saine (confiance: 1.000)\n",
      "ViT-2           → Saine (confiance: 1.000)\n",
      "--------------------------------------------------\n",
      "\n",
      "==> Analyzing: ISIC_0024313_1.jpg\n",
      "\n",
      "--------------------------------------------------\n",
      "Custom CNN      → Saine (confiance: 0.892)\n",
      "VGG16           → Saine (confiance: 0.926)\n",
      "ViT-1           → Saine (confiance: 0.971)\n",
      "ViT-2           → Saine (confiance: 0.945)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T17:15:26.930348200Z",
     "start_time": "2026-01-14T17:15:26.901059700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "models_dir = \"../etape1/models\"\n",
    "if os.path.exists(models_dir):\n",
    "    print(\"Available model files:\")\n",
    "    for f in sorted(os.listdir(models_dir)):\n",
    "        if f.endswith('.pth'):\n",
    "            print(f\"  - {f}\")\n",
    "else:\n",
    "    print(f\"Directory not found: {models_dir}\")"
   ],
   "id": "17e06c7190b28c41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model files:\n",
      "  - CustomCNN.pth\n",
      "  - VGG16.pth\n",
      "  - ViT-1.pth\n",
      "  - ViT-2.pth\n"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
